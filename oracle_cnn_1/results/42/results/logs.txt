[CONDUCTOR]: Begin experiment at /mnt/wd500GB/CSC500/csc500-super-repo/csc500-homenet-experiments/oracle_cnn_1/results/42
WARNING: CPU random generator seem to be failing, disable hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(oracle_cnn_driver.py:447338): Gdk-CRITICAL **: 13:40:41.423: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1750], examples_per_second: 768.9082, train_label_loss: 2.7314, 
epoch: 1, [batch: 175 / 1750], examples_per_second: 3892.2068, train_label_loss: 1.4145, 
epoch: 1, [batch: 350 / 1750], examples_per_second: 3928.5627, train_label_loss: 0.7408, 
epoch: 1, [batch: 525 / 1750], examples_per_second: 2621.1412, train_label_loss: 0.8918, 
epoch: 1, [batch: 700 / 1750], examples_per_second: 2336.5423, train_label_loss: 0.3984, 
epoch: 1, [batch: 875 / 1750], examples_per_second: 2309.4063, train_label_loss: 0.3743, 
epoch: 1, [batch: 1050 / 1750], examples_per_second: 2287.2318, train_label_loss: 0.3867, 
epoch: 1, [batch: 1225 / 1750], examples_per_second: 2274.7539, train_label_loss: 0.2066, 
epoch: 1, [batch: 1400 / 1750], examples_per_second: 2279.0184, train_label_loss: 0.1962, 
epoch: 1, [batch: 1575 / 1750], examples_per_second: 2242.1443, train_label_loss: 0.2619, 
=============================================================
epoch: 1, source_val_acc_label: 0.9651, source_val_label_loss: 0.1690, target_val_acc_label: 0.0525, target_val_label_loss: 91.3620, 
=============================================================
New best
epoch: 2, [batch: 1 / 1750], examples_per_second: 3.6980, train_label_loss: 0.1365, 
epoch: 2, [batch: 175 / 1750], examples_per_second: 2095.8719, train_label_loss: 0.2847, 
epoch: 2, [batch: 350 / 1750], examples_per_second: 2086.0345, train_label_loss: 0.1347, 
epoch: 2, [batch: 525 / 1750], examples_per_second: 2071.4872, train_label_loss: 0.3321, 
epoch: 2, [batch: 700 / 1750], examples_per_second: 2053.4630, train_label_loss: 0.1352, 
epoch: 2, [batch: 875 / 1750], examples_per_second: 2039.8163, train_label_loss: 0.1503, 
epoch: 2, [batch: 1050 / 1750], examples_per_second: 2011.1446, train_label_loss: 0.2236, 
epoch: 2, [batch: 1225 / 1750], examples_per_second: 1988.8725, train_label_loss: 0.1331, 
epoch: 2, [batch: 1400 / 1750], examples_per_second: 1971.4534, train_label_loss: 0.1632, 
epoch: 2, [batch: 1575 / 1750], examples_per_second: 1944.0302, train_label_loss: 0.1555, 
=============================================================
epoch: 2, source_val_acc_label: 0.9675, source_val_label_loss: 0.1150, target_val_acc_label: 0.0516, target_val_label_loss: 169.9471, 
=============================================================
New best
epoch: 3, [batch: 1 / 1750], examples_per_second: 3.1452, train_label_loss: 0.0588, 
epoch: 3, [batch: 175 / 1750], examples_per_second: 3136.1152, train_label_loss: 0.0749, 
epoch: 3, [batch: 350 / 1750], examples_per_second: 2596.3017, train_label_loss: 0.1165, 
epoch: 3, [batch: 525 / 1750], examples_per_second: 2312.4771, train_label_loss: 0.0675, 
epoch: 3, [batch: 700 / 1750], examples_per_second: 2275.3284, train_label_loss: 0.0641, 
epoch: 3, [batch: 875 / 1750], examples_per_second: 2272.5329, train_label_loss: 0.0819, 
epoch: 3, [batch: 1050 / 1750], examples_per_second: 2253.1265, train_label_loss: 0.0831, 
epoch: 3, [batch: 1225 / 1750], examples_per_second: 2234.9012, train_label_loss: 0.0406, 
epoch: 3, [batch: 1400 / 1750], examples_per_second: 2235.8186, train_label_loss: 0.0368, 
epoch: 3, [batch: 1575 / 1750], examples_per_second: 2194.5022, train_label_loss: 0.1464, 
=============================================================
epoch: 3, source_val_acc_label: 0.9669, source_val_label_loss: 0.1055, target_val_acc_label: 0.0500, target_val_label_loss: 234.1308, 
=============================================================
New best
epoch: 4, [batch: 1 / 1750], examples_per_second: 3.3827, train_label_loss: 0.1462, 
epoch: 4, [batch: 175 / 1750], examples_per_second: 1985.2667, train_label_loss: 0.0660, 
epoch: 4, [batch: 350 / 1750], examples_per_second: 1973.6264, train_label_loss: 0.2183, 
epoch: 4, [batch: 525 / 1750], examples_per_second: 2312.9970, train_label_loss: 0.0647, 
epoch: 4, [batch: 700 / 1750], examples_per_second: 2294.8623, train_label_loss: 0.0247, 
epoch: 4, [batch: 875 / 1750], examples_per_second: 2278.8822, train_label_loss: 0.0446, 
epoch: 4, [batch: 1050 / 1750], examples_per_second: 2258.9535, train_label_loss: 0.0893, 
epoch: 4, [batch: 1225 / 1750], examples_per_second: 2252.2270, train_label_loss: 0.1140, 
epoch: 4, [batch: 1400 / 1750], examples_per_second: 2239.3719, train_label_loss: 0.0644, 
epoch: 4, [batch: 1575 / 1750], examples_per_second: 2216.0580, train_label_loss: 0.1105, 
=============================================================
epoch: 4, source_val_acc_label: 0.9715, source_val_label_loss: 0.0901, target_val_acc_label: 0.0564, target_val_label_loss: 432.3344, 
=============================================================
New best
epoch: 5, [batch: 1 / 1750], examples_per_second: 3.4562, train_label_loss: 0.0615, 
epoch: 5, [batch: 175 / 1750], examples_per_second: 2003.1822, train_label_loss: 0.0622, 
epoch: 5, [batch: 350 / 1750], examples_per_second: 1988.0043, train_label_loss: 0.0882, 
epoch: 5, [batch: 525 / 1750], examples_per_second: 1968.2916, train_label_loss: 0.0561, 
epoch: 5, [batch: 700 / 1750], examples_per_second: 2840.0697, train_label_loss: 0.0322, 
epoch: 5, [batch: 875 / 1750], examples_per_second: 3935.3558, train_label_loss: 0.0366, 
epoch: 5, [batch: 1050 / 1750], examples_per_second: 3931.5435, train_label_loss: 0.0734, 
epoch: 5, [batch: 1225 / 1750], examples_per_second: 3935.0038, train_label_loss: 0.0509, 
epoch: 5, [batch: 1400 / 1750], examples_per_second: 3930.2248, train_label_loss: 0.0411, 
epoch: 5, [batch: 1575 / 1750], examples_per_second: 3934.7028, train_label_loss: 0.0733, 
=============================================================
epoch: 5, source_val_acc_label: 0.9669, source_val_label_loss: 0.0989, target_val_acc_label: 0.0570, target_val_label_loss: 451.9970, 
=============================================================
epoch: 6, [batch: 1 / 1750], examples_per_second: 7.3633, train_label_loss: 0.0446, 
epoch: 6, [batch: 175 / 1750], examples_per_second: 3931.3270, train_label_loss: 0.0576, 
epoch: 6, [batch: 350 / 1750], examples_per_second: 3934.2438, train_label_loss: 0.0473, 
epoch: 6, [batch: 525 / 1750], examples_per_second: 3932.5628, train_label_loss: 0.0603, 
epoch: 6, [batch: 700 / 1750], examples_per_second: 3933.6653, train_label_loss: 0.0562, 
epoch: 6, [batch: 875 / 1750], examples_per_second: 3929.4381, train_label_loss: 0.0277, 
epoch: 6, [batch: 1050 / 1750], examples_per_second: 2600.8100, train_label_loss: 0.0891, 
epoch: 6, [batch: 1225 / 1750], examples_per_second: 2342.9425, train_label_loss: 0.0550, 
epoch: 6, [batch: 1400 / 1750], examples_per_second: 2315.7170, train_label_loss: 0.0222, 
epoch: 6, [batch: 1575 / 1750], examples_per_second: 2287.0792, train_label_loss: 0.0289, 
=============================================================
epoch: 6, source_val_acc_label: 0.9677, source_val_label_loss: 0.0950, target_val_acc_label: 0.0540, target_val_label_loss: 807.2174, 
=============================================================
epoch: 7, [batch: 1 / 1750], examples_per_second: 3.8545, train_label_loss: 0.0425, 
epoch: 7, [batch: 175 / 1750], examples_per_second: 2166.8682, train_label_loss: 0.0117, 
epoch: 7, [batch: 350 / 1750], examples_per_second: 2172.1590, train_label_loss: 0.0538, 
epoch: 7, [batch: 525 / 1750], examples_per_second: 2118.9520, train_label_loss: 0.0507, 
epoch: 7, [batch: 700 / 1750], examples_per_second: 2124.4370, train_label_loss: 0.1451, 
epoch: 7, [batch: 875 / 1750], examples_per_second: 2113.2719, train_label_loss: 0.0327, 
epoch: 7, [batch: 1050 / 1750], examples_per_second: 2071.9319, train_label_loss: 0.1160, 
epoch: 7, [batch: 1225 / 1750], examples_per_second: 2073.3390, train_label_loss: 0.0207, 
epoch: 7, [batch: 1400 / 1750], examples_per_second: 2049.3204, train_label_loss: 0.0589, 
epoch: 7, [batch: 1575 / 1750], examples_per_second: 2032.9172, train_label_loss: 0.1024, 
=============================================================
epoch: 7, source_val_acc_label: 0.9532, source_val_label_loss: 0.1375, target_val_acc_label: 0.0537, target_val_label_loss: 706.0210, 
=============================================================
epoch: 8, [batch: 1 / 1750], examples_per_second: 3.0397, train_label_loss: 0.0382, 
epoch: 8, [batch: 175 / 1750], examples_per_second: 2168.3834, train_label_loss: 0.0894, 
epoch: 8, [batch: 350 / 1750], examples_per_second: 2146.8445, train_label_loss: 0.0689, 
epoch: 8, [batch: 525 / 1750], examples_per_second: 2132.4892, train_label_loss: 0.0143, 
epoch: 8, [batch: 700 / 1750], examples_per_second: 2499.1929, train_label_loss: 0.0415, 
epoch: 8, [batch: 875 / 1750], examples_per_second: 3029.0026, train_label_loss: 0.1387, 
epoch: 8, [batch: 1050 / 1750], examples_per_second: 2306.4923, train_label_loss: 0.0250, 
epoch: 8, [batch: 1225 / 1750], examples_per_second: 2267.6389, train_label_loss: 0.0487, 
epoch: 8, [batch: 1400 / 1750], examples_per_second: 2272.6999, train_label_loss: 0.0544, 
epoch: 8, [batch: 1575 / 1750], examples_per_second: 2253.3844, train_label_loss: 0.0281, 
=============================================================
epoch: 8, source_val_acc_label: 0.9593, source_val_label_loss: 0.1221, target_val_acc_label: 0.0543, target_val_label_loss: 784.4517, 
=============================================================
epoch: 9, [batch: 1 / 1750], examples_per_second: 3.5888, train_label_loss: 0.0153, 
epoch: 9, [batch: 175 / 1750], examples_per_second: 2065.8730, train_label_loss: 0.0768, 
epoch: 9, [batch: 350 / 1750], examples_per_second: 2051.7891, train_label_loss: 0.0472, 
epoch: 9, [batch: 525 / 1750], examples_per_second: 2016.4900, train_label_loss: 0.0268, 
epoch: 9, [batch: 700 / 1750], examples_per_second: 1989.1628, train_label_loss: 0.0073, 
epoch: 9, [batch: 875 / 1750], examples_per_second: 1961.5084, train_label_loss: 0.0381, 
epoch: 9, [batch: 1050 / 1750], examples_per_second: 2127.1014, train_label_loss: 0.0134, 
epoch: 9, [batch: 1225 / 1750], examples_per_second: 2299.9880, train_label_loss: 0.0234, 
epoch: 9, [batch: 1400 / 1750], examples_per_second: 2277.5277, train_label_loss: 0.0122, 
epoch: 9, [batch: 1575 / 1750], examples_per_second: 2266.7989, train_label_loss: 0.0406, 
=============================================================
epoch: 9, source_val_acc_label: 0.9575, source_val_label_loss: 0.1264, target_val_acc_label: 0.0551, target_val_label_loss: 828.2224, 
=============================================================
epoch: 10, [batch: 1 / 1750], examples_per_second: 3.6609, train_label_loss: 0.0441, 
epoch: 10, [batch: 175 / 1750], examples_per_second: 2099.0904, train_label_loss: 0.0085, 
epoch: 10, [batch: 350 / 1750], examples_per_second: 2076.3136, train_label_loss: 0.0127, 
epoch: 10, [batch: 525 / 1750], examples_per_second: 2067.4207, train_label_loss: 0.0090, 
epoch: 10, [batch: 700 / 1750], examples_per_second: 2017.7691, train_label_loss: 0.0489, 
epoch: 10, [batch: 875 / 1750], examples_per_second: 1997.2267, train_label_loss: 0.0194, 
epoch: 10, [batch: 1050 / 1750], examples_per_second: 1982.2790, train_label_loss: 0.0788, 
epoch: 10, [batch: 1225 / 1750], examples_per_second: 1968.8388, train_label_loss: 0.0110, 
epoch: 10, [batch: 1400 / 1750], examples_per_second: 3358.7876, train_label_loss: 0.0090, 
epoch: 10, [batch: 1575 / 1750], examples_per_second: 3927.4880, train_label_loss: 0.0266, 
=============================================================
epoch: 10, source_val_acc_label: 0.9627, source_val_label_loss: 0.1152, target_val_acc_label: 0.0534, target_val_label_loss: 1320.8341, 
=============================================================
epoch: 11, [batch: 1 / 1750], examples_per_second: 7.3703, train_label_loss: 0.0086, 
epoch: 11, [batch: 175 / 1750], examples_per_second: 3933.3312, train_label_loss: 0.0095, 
epoch: 11, [batch: 350 / 1750], examples_per_second: 3931.7890, train_label_loss: 0.0084, 
epoch: 11, [batch: 525 / 1750], examples_per_second: 3934.1311, train_label_loss: 0.0186, 
epoch: 11, [batch: 700 / 1750], examples_per_second: 3932.9003, train_label_loss: 0.0468, 
epoch: 11, [batch: 875 / 1750], examples_per_second: 3932.5858, train_label_loss: 0.0403, 
epoch: 11, [batch: 1050 / 1750], examples_per_second: 3934.4995, train_label_loss: 0.0496, 
epoch: 11, [batch: 1225 / 1750], examples_per_second: 3929.3734, train_label_loss: 0.0028, 
epoch: 11, [batch: 1400 / 1750], examples_per_second: 3935.6977, train_label_loss: 0.0468, 
epoch: 11, [batch: 1575 / 1750], examples_per_second: 3717.7260, train_label_loss: 0.0160, 
=============================================================
epoch: 11, source_val_acc_label: 0.9629, source_val_label_loss: 0.1135, target_val_acc_label: 0.0545, target_val_label_loss: 1188.8828, 
=============================================================
epoch: 12, [batch: 1 / 1750], examples_per_second: 3.9636, train_label_loss: 0.0061, 
epoch: 12, [batch: 175 / 1750], examples_per_second: 2242.6489, train_label_loss: 0.0643, 
epoch: 12, [batch: 350 / 1750], examples_per_second: 2209.0597, train_label_loss: 0.0108, 
epoch: 12, [batch: 525 / 1750], examples_per_second: 2177.3649, train_label_loss: 0.0107, 
epoch: 12, [batch: 700 / 1750], examples_per_second: 2194.9556, train_label_loss: 0.0060, 
epoch: 12, [batch: 875 / 1750], examples_per_second: 2167.3439, train_label_loss: 0.0091, 
epoch: 12, [batch: 1050 / 1750], examples_per_second: 2158.8476, train_label_loss: 0.0516, 
epoch: 12, [batch: 1225 / 1750], examples_per_second: 2154.3516, train_label_loss: 0.0421, 
epoch: 12, [batch: 1400 / 1750], examples_per_second: 2088.8305, train_label_loss: 0.0657, 
epoch: 12, [batch: 1575 / 1750], examples_per_second: 2114.1683, train_label_loss: 0.0104, 
=============================================================
epoch: 12, source_val_acc_label: 0.9643, source_val_label_loss: 0.1157, target_val_acc_label: 0.0541, target_val_label_loss: 1526.9253, 
=============================================================
epoch: 13, [batch: 1 / 1750], examples_per_second: 3.2322, train_label_loss: 0.0044, 
epoch: 13, [batch: 175 / 1750], examples_per_second: 1886.2718, train_label_loss: 0.0172, 
epoch: 13, [batch: 350 / 1750], examples_per_second: 1840.1145, train_label_loss: 0.0087, 
epoch: 13, [batch: 525 / 1750], examples_per_second: 1805.1267, train_label_loss: 0.0104, 
epoch: 13, [batch: 700 / 1750], examples_per_second: 2009.4893, train_label_loss: 0.0454, 
epoch: 13, [batch: 875 / 1750], examples_per_second: 2153.2702, train_label_loss: 0.0036, 
epoch: 13, [batch: 1050 / 1750], examples_per_second: 2159.8913, train_label_loss: 0.0190, 
epoch: 13, [batch: 1225 / 1750], examples_per_second: 2122.2729, train_label_loss: 0.0130, 
epoch: 13, [batch: 1400 / 1750], examples_per_second: 2635.2133, train_label_loss: 0.0069, 
epoch: 13, [batch: 1575 / 1750], examples_per_second: 2882.2288, train_label_loss: 0.0369, 
=============================================================
epoch: 13, source_val_acc_label: 0.9643, source_val_label_loss: 0.1132, target_val_acc_label: 0.0542, target_val_label_loss: 1651.0909, 
=============================================================
epoch: 14, [batch: 1 / 1750], examples_per_second: 3.8061, train_label_loss: 0.0119, 
epoch: 14, [batch: 175 / 1750], examples_per_second: 2160.5274, train_label_loss: 0.0084, 
epoch: 14, [batch: 350 / 1750], examples_per_second: 2155.0854, train_label_loss: 0.0081, 
epoch: 14, [batch: 525 / 1750], examples_per_second: 2117.9105, train_label_loss: 0.0168, 
epoch: 14, [batch: 700 / 1750], examples_per_second: 2083.9208, train_label_loss: 0.0070, 
epoch: 14, [batch: 875 / 1750], examples_per_second: 2065.5496, train_label_loss: 0.0125, 
epoch: 14, [batch: 1050 / 1750], examples_per_second: 2057.0461, train_label_loss: 0.0094, 
epoch: 14, [batch: 1225 / 1750], examples_per_second: 2017.3447, train_label_loss: 0.0339, 
epoch: 14, [batch: 1400 / 1750], examples_per_second: 1998.3678, train_label_loss: 0.0284, 
epoch: 14, [batch: 1575 / 1750], examples_per_second: 1964.3133, train_label_loss: 0.0598, 
=============================================================
epoch: 14, source_val_acc_label: 0.9475, source_val_label_loss: 0.1695, target_val_acc_label: 0.0528, target_val_label_loss: 1379.4464, 
=============================================================
epoch: 15, [batch: 1 / 1750], examples_per_second: 3.8041, train_label_loss: 0.0608, 
epoch: 15, [batch: 175 / 1750], examples_per_second: 2202.7818, train_label_loss: 0.0200, 
epoch: 15, [batch: 350 / 1750], examples_per_second: 2157.9532, train_label_loss: 0.0130, 
epoch: 15, [batch: 525 / 1750], examples_per_second: 2149.7988, train_label_loss: 0.0970, 
epoch: 15, [batch: 700 / 1750], examples_per_second: 2148.0466, train_label_loss: 0.0028, 
epoch: 15, [batch: 875 / 1750], examples_per_second: 2116.2888, train_label_loss: 0.0349, 
epoch: 15, [batch: 1050 / 1750], examples_per_second: 2099.7023, train_label_loss: 0.0024, 
epoch: 15, [batch: 1225 / 1750], examples_per_second: 2068.1611, train_label_loss: 0.0064, 
epoch: 15, [batch: 1400 / 1750], examples_per_second: 2040.1724, train_label_loss: 0.0497, 
epoch: 15, [batch: 1575 / 1750], examples_per_second: 1994.3711, train_label_loss: 0.0168, 
=============================================================
epoch: 15, source_val_acc_label: 0.9536, source_val_label_loss: 0.1483, target_val_acc_label: 0.0527, target_val_label_loss: 1384.6651, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.9712916666666667 Target Test Label Accuracy: 0.05629166666666666
Source Val Label Accuracy: 0.9715 Target Val Label Accuracy: 0.0564125
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
