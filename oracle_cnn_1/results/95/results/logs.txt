[CONDUCTOR]: Begin experiment at /mnt/wd500GB/CSC500/csc500-super-repo/csc500-homenet-experiments/oracle_cnn_1/results/95
WARNING: CPU random generator seem to be failing, disable hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(oracle_cnn_driver.py:463125): Gdk-CRITICAL **: 20:45:31.615: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1750], examples_per_second: 722.4863, train_label_loss: 2.7777, 
epoch: 1, [batch: 175 / 1750], examples_per_second: 3890.1026, train_label_loss: 1.7638, 
epoch: 1, [batch: 350 / 1750], examples_per_second: 3924.4245, train_label_loss: 1.2118, 
epoch: 1, [batch: 525 / 1750], examples_per_second: 3923.0785, train_label_loss: 1.0388, 
epoch: 1, [batch: 700 / 1750], examples_per_second: 3926.1855, train_label_loss: 0.9026, 
epoch: 1, [batch: 875 / 1750], examples_per_second: 3933.0465, train_label_loss: 0.8032, 
epoch: 1, [batch: 1050 / 1750], examples_per_second: 3921.8850, train_label_loss: 0.7593, 
epoch: 1, [batch: 1225 / 1750], examples_per_second: 3921.9717, train_label_loss: 0.6857, 
epoch: 1, [batch: 1400 / 1750], examples_per_second: 3915.1712, train_label_loss: 0.5766, 
epoch: 1, [batch: 1575 / 1750], examples_per_second: 3923.0336, train_label_loss: 0.5674, 
=============================================================
epoch: 1, source_val_acc_label: 0.8239, source_val_label_loss: 0.5339, target_val_acc_label: 0.0592, target_val_label_loss: 164.2936, 
=============================================================
New best
epoch: 2, [batch: 1 / 1750], examples_per_second: 7.2817, train_label_loss: 0.5007, 
epoch: 2, [batch: 175 / 1750], examples_per_second: 3920.7230, train_label_loss: 0.4989, 
epoch: 2, [batch: 350 / 1750], examples_per_second: 3923.2669, train_label_loss: 0.7155, 
epoch: 2, [batch: 525 / 1750], examples_per_second: 3924.0872, train_label_loss: 0.3440, 
epoch: 2, [batch: 700 / 1750], examples_per_second: 3925.4329, train_label_loss: 0.4330, 
epoch: 2, [batch: 875 / 1750], examples_per_second: 3925.2400, train_label_loss: 0.4489, 
epoch: 2, [batch: 1050 / 1750], examples_per_second: 3927.3583, train_label_loss: 0.4944, 
epoch: 2, [batch: 1225 / 1750], examples_per_second: 3924.8402, train_label_loss: 0.4167, 
epoch: 2, [batch: 1400 / 1750], examples_per_second: 3928.0834, train_label_loss: 0.6351, 
epoch: 2, [batch: 1575 / 1750], examples_per_second: 3921.3304, train_label_loss: 0.5756, 
=============================================================
epoch: 2, source_val_acc_label: 0.8679, source_val_label_loss: 0.3853, target_val_acc_label: 0.0640, target_val_label_loss: 215.6748, 
=============================================================
New best
epoch: 3, [batch: 1 / 1750], examples_per_second: 7.3363, train_label_loss: 0.3453, 
epoch: 3, [batch: 175 / 1750], examples_per_second: 3918.6704, train_label_loss: 0.2199, 
epoch: 3, [batch: 350 / 1750], examples_per_second: 3923.3314, train_label_loss: 0.4428, 
epoch: 3, [batch: 525 / 1750], examples_per_second: 3917.0663, train_label_loss: 0.4327, 
epoch: 3, [batch: 700 / 1750], examples_per_second: 3921.9236, train_label_loss: 0.3451, 
epoch: 3, [batch: 875 / 1750], examples_per_second: 3921.7344, train_label_loss: 0.2425, 
epoch: 3, [batch: 1050 / 1750], examples_per_second: 3925.0645, train_label_loss: 0.2394, 
epoch: 3, [batch: 1225 / 1750], examples_per_second: 3924.9219, train_label_loss: 0.2390, 
epoch: 3, [batch: 1400 / 1750], examples_per_second: 3929.7856, train_label_loss: 0.4284, 
epoch: 3, [batch: 1575 / 1750], examples_per_second: 3922.5268, train_label_loss: 0.3879, 
=============================================================
epoch: 3, source_val_acc_label: 0.8769, source_val_label_loss: 0.3377, target_val_acc_label: 0.0582, target_val_label_loss: 338.2254, 
=============================================================
New best
epoch: 4, [batch: 1 / 1750], examples_per_second: 7.3202, train_label_loss: 0.2254, 
epoch: 4, [batch: 175 / 1750], examples_per_second: 3922.1157, train_label_loss: 0.2033, 
epoch: 4, [batch: 350 / 1750], examples_per_second: 3922.6968, train_label_loss: 0.4880, 
epoch: 4, [batch: 525 / 1750], examples_per_second: 3927.3599, train_label_loss: 0.3010, 
epoch: 4, [batch: 700 / 1750], examples_per_second: 3920.3225, train_label_loss: 0.3173, 
epoch: 4, [batch: 875 / 1750], examples_per_second: 3925.2551, train_label_loss: 0.4006, 
epoch: 4, [batch: 1050 / 1750], examples_per_second: 3923.9390, train_label_loss: 0.1647, 
epoch: 4, [batch: 1225 / 1750], examples_per_second: 3927.1932, train_label_loss: 0.3815, 
epoch: 4, [batch: 1400 / 1750], examples_per_second: 3925.1337, train_label_loss: 0.1648, 
epoch: 4, [batch: 1575 / 1750], examples_per_second: 3920.0938, train_label_loss: 0.3906, 
=============================================================
epoch: 4, source_val_acc_label: 0.8820, source_val_label_loss: 0.3146, target_val_acc_label: 0.0578, target_val_label_loss: 380.0490, 
=============================================================
New best
epoch: 5, [batch: 1 / 1750], examples_per_second: 7.3177, train_label_loss: 0.3997, 
epoch: 5, [batch: 175 / 1750], examples_per_second: 3927.1707, train_label_loss: 0.1380, 
epoch: 5, [batch: 350 / 1750], examples_per_second: 3921.9174, train_label_loss: 0.4438, 
epoch: 5, [batch: 525 / 1750], examples_per_second: 3932.4120, train_label_loss: 0.0968, 
epoch: 5, [batch: 700 / 1750], examples_per_second: 3918.3114, train_label_loss: 0.1870, 
epoch: 5, [batch: 875 / 1750], examples_per_second: 3921.8005, train_label_loss: 0.1214, 
epoch: 5, [batch: 1050 / 1750], examples_per_second: 3921.9757, train_label_loss: 0.1617, 
epoch: 5, [batch: 1225 / 1750], examples_per_second: 3925.3565, train_label_loss: 0.1922, 
epoch: 5, [batch: 1400 / 1750], examples_per_second: 3922.5357, train_label_loss: 0.3095, 
epoch: 5, [batch: 1575 / 1750], examples_per_second: 3927.8246, train_label_loss: 0.1904, 
=============================================================
epoch: 5, source_val_acc_label: 0.8770, source_val_label_loss: 0.3165, target_val_acc_label: 0.0588, target_val_label_loss: 486.6070, 
=============================================================
epoch: 6, [batch: 1 / 1750], examples_per_second: 7.3345, train_label_loss: 0.1247, 
epoch: 6, [batch: 175 / 1750], examples_per_second: 3741.0090, train_label_loss: 0.1632, 
epoch: 6, [batch: 350 / 1750], examples_per_second: 3929.3931, train_label_loss: 0.2217, 
epoch: 6, [batch: 525 / 1750], examples_per_second: 3921.2400, train_label_loss: 0.1047, 
epoch: 6, [batch: 700 / 1750], examples_per_second: 3928.5003, train_label_loss: 0.1493, 
epoch: 6, [batch: 875 / 1750], examples_per_second: 3929.0174, train_label_loss: 0.1505, 
epoch: 6, [batch: 1050 / 1750], examples_per_second: 3918.1366, train_label_loss: 0.0942, 
epoch: 6, [batch: 1225 / 1750], examples_per_second: 3922.7145, train_label_loss: 0.3148, 
epoch: 6, [batch: 1400 / 1750], examples_per_second: 3921.6928, train_label_loss: 0.1592, 
epoch: 6, [batch: 1575 / 1750], examples_per_second: 3926.4493, train_label_loss: 0.2653, 
=============================================================
epoch: 6, source_val_acc_label: 0.8686, source_val_label_loss: 0.3427, target_val_acc_label: 0.0596, target_val_label_loss: 583.4345, 
=============================================================
epoch: 7, [batch: 1 / 1750], examples_per_second: 4.2278, train_label_loss: 0.2072, 
epoch: 7, [batch: 175 / 1750], examples_per_second: 2220.8794, train_label_loss: 0.0743, 
epoch: 7, [batch: 350 / 1750], examples_per_second: 2227.5873, train_label_loss: 0.1095, 
epoch: 7, [batch: 525 / 1750], examples_per_second: 2214.5854, train_label_loss: 0.1504, 
epoch: 7, [batch: 700 / 1750], examples_per_second: 2228.3093, train_label_loss: 0.0907, 
epoch: 7, [batch: 875 / 1750], examples_per_second: 2165.5150, train_label_loss: 0.1097, 
epoch: 7, [batch: 1050 / 1750], examples_per_second: 2172.0763, train_label_loss: 0.0892, 
epoch: 7, [batch: 1225 / 1750], examples_per_second: 2159.1695, train_label_loss: 0.0944, 
epoch: 7, [batch: 1400 / 1750], examples_per_second: 2153.7803, train_label_loss: 0.1043, 
epoch: 7, [batch: 1575 / 1750], examples_per_second: 2118.4686, train_label_loss: 0.1616, 
=============================================================
epoch: 7, source_val_acc_label: 0.8730, source_val_label_loss: 0.3426, target_val_acc_label: 0.0587, target_val_label_loss: 622.0800, 
=============================================================
epoch: 8, [batch: 1 / 1750], examples_per_second: 3.3124, train_label_loss: 0.0580, 
epoch: 8, [batch: 175 / 1750], examples_per_second: 1910.0557, train_label_loss: 0.0927, 
epoch: 8, [batch: 350 / 1750], examples_per_second: 1881.8288, train_label_loss: 0.1518, 
epoch: 8, [batch: 525 / 1750], examples_per_second: 1853.5233, train_label_loss: 0.0795, 
epoch: 8, [batch: 700 / 1750], examples_per_second: 1809.5247, train_label_loss: 0.0675, 
epoch: 8, [batch: 875 / 1750], examples_per_second: 1777.9356, train_label_loss: 0.1682, 
epoch: 8, [batch: 1050 / 1750], examples_per_second: 2337.0595, train_label_loss: 0.0685, 
epoch: 8, [batch: 1225 / 1750], examples_per_second: 2101.8541, train_label_loss: 0.0556, 
epoch: 8, [batch: 1400 / 1750], examples_per_second: 2180.2581, train_label_loss: 0.0969, 
epoch: 8, [batch: 1575 / 1750], examples_per_second: 2217.5942, train_label_loss: 0.1109, 
=============================================================
epoch: 8, source_val_acc_label: 0.8663, source_val_label_loss: 0.3679, target_val_acc_label: 0.0568, target_val_label_loss: 683.4006, 
=============================================================
epoch: 9, [batch: 1 / 1750], examples_per_second: 4.0724, train_label_loss: 0.0537, 
epoch: 9, [batch: 175 / 1750], examples_per_second: 2186.0976, train_label_loss: 0.0452, 
epoch: 9, [batch: 350 / 1750], examples_per_second: 2180.9398, train_label_loss: 0.0490, 
epoch: 9, [batch: 525 / 1750], examples_per_second: 2152.2285, train_label_loss: 0.0237, 
epoch: 9, [batch: 700 / 1750], examples_per_second: 2118.3844, train_label_loss: 0.0386, 
epoch: 9, [batch: 875 / 1750], examples_per_second: 2100.7884, train_label_loss: 0.3840, 
epoch: 9, [batch: 1050 / 1750], examples_per_second: 2088.1321, train_label_loss: 0.0354, 
epoch: 9, [batch: 1225 / 1750], examples_per_second: 2072.7985, train_label_loss: 0.2595, 
epoch: 9, [batch: 1400 / 1750], examples_per_second: 2035.2027, train_label_loss: 0.0825, 
epoch: 9, [batch: 1575 / 1750], examples_per_second: 2013.3976, train_label_loss: 0.1306, 
=============================================================
epoch: 9, source_val_acc_label: 0.8625, source_val_label_loss: 0.4003, target_val_acc_label: 0.0584, target_val_label_loss: 734.7054, 
=============================================================
epoch: 10, [batch: 1 / 1750], examples_per_second: 3.6652, train_label_loss: 0.0172, 
epoch: 10, [batch: 175 / 1750], examples_per_second: 2214.0014, train_label_loss: 0.0679, 
epoch: 10, [batch: 350 / 1750], examples_per_second: 2195.7670, train_label_loss: 0.0759, 
epoch: 10, [batch: 525 / 1750], examples_per_second: 2188.6910, train_label_loss: 0.0387, 
epoch: 10, [batch: 700 / 1750], examples_per_second: 2153.4904, train_label_loss: 0.0395, 
epoch: 10, [batch: 875 / 1750], examples_per_second: 2140.2305, train_label_loss: 0.2243, 
epoch: 10, [batch: 1050 / 1750], examples_per_second: 2105.1770, train_label_loss: 0.0766, 
epoch: 10, [batch: 1225 / 1750], examples_per_second: 2110.1559, train_label_loss: 0.0688, 
epoch: 10, [batch: 1400 / 1750], examples_per_second: 2070.6283, train_label_loss: 0.0431, 
epoch: 10, [batch: 1575 / 1750], examples_per_second: 2049.9633, train_label_loss: 0.0786, 
=============================================================
epoch: 10, source_val_acc_label: 0.8603, source_val_label_loss: 0.4009, target_val_acc_label: 0.0565, target_val_label_loss: 789.0021, 
=============================================================
epoch: 11, [batch: 1 / 1750], examples_per_second: 4.5364, train_label_loss: 0.0392, 
epoch: 11, [batch: 175 / 1750], examples_per_second: 3926.4725, train_label_loss: 0.0295, 
epoch: 11, [batch: 350 / 1750], examples_per_second: 3920.9841, train_label_loss: 0.0697, 
epoch: 11, [batch: 525 / 1750], examples_per_second: 3931.0546, train_label_loss: 0.1661, 
epoch: 11, [batch: 700 / 1750], examples_per_second: 3926.3650, train_label_loss: 0.0643, 
epoch: 11, [batch: 875 / 1750], examples_per_second: 3920.1759, train_label_loss: 0.1258, 
epoch: 11, [batch: 1050 / 1750], examples_per_second: 3926.6115, train_label_loss: 0.1532, 
epoch: 11, [batch: 1225 / 1750], examples_per_second: 3920.7985, train_label_loss: 0.0547, 
epoch: 11, [batch: 1400 / 1750], examples_per_second: 3929.2781, train_label_loss: 0.0842, 
epoch: 11, [batch: 1575 / 1750], examples_per_second: 3920.7046, train_label_loss: 0.0513, 
=============================================================
epoch: 11, source_val_acc_label: 0.8616, source_val_label_loss: 0.4069, target_val_acc_label: 0.0581, target_val_label_loss: 867.8618, 
=============================================================
epoch: 12, [batch: 1 / 1750], examples_per_second: 6.4480, train_label_loss: 0.0166, 
epoch: 12, [batch: 175 / 1750], examples_per_second: 2338.2375, train_label_loss: 0.0233, 
epoch: 12, [batch: 350 / 1750], examples_per_second: 2327.5006, train_label_loss: 0.0744, 
epoch: 12, [batch: 525 / 1750], examples_per_second: 2296.3138, train_label_loss: 0.0161, 
epoch: 12, [batch: 700 / 1750], examples_per_second: 2269.9485, train_label_loss: 0.0558, 
epoch: 12, [batch: 875 / 1750], examples_per_second: 2241.2177, train_label_loss: 0.0527, 
epoch: 12, [batch: 1050 / 1750], examples_per_second: 2233.4942, train_label_loss: 0.0296, 
epoch: 12, [batch: 1225 / 1750], examples_per_second: 2281.4390, train_label_loss: 0.0940, 
epoch: 12, [batch: 1400 / 1750], examples_per_second: 2219.3300, train_label_loss: 0.0168, 
epoch: 12, [batch: 1575 / 1750], examples_per_second: 2213.3419, train_label_loss: 0.0393, 
=============================================================
epoch: 12, source_val_acc_label: 0.8564, source_val_label_loss: 0.4361, target_val_acc_label: 0.0578, target_val_label_loss: 912.5513, 
=============================================================
epoch: 13, [batch: 1 / 1750], examples_per_second: 3.5986, train_label_loss: 0.0187, 
epoch: 13, [batch: 175 / 1750], examples_per_second: 2061.2534, train_label_loss: 0.0635, 
epoch: 13, [batch: 350 / 1750], examples_per_second: 2037.2698, train_label_loss: 0.0355, 
epoch: 13, [batch: 525 / 1750], examples_per_second: 1996.4881, train_label_loss: 0.0539, 
epoch: 13, [batch: 700 / 1750], examples_per_second: 1991.6268, train_label_loss: 0.0264, 
epoch: 13, [batch: 875 / 1750], examples_per_second: 1952.8911, train_label_loss: 0.0081, 
epoch: 13, [batch: 1050 / 1750], examples_per_second: 1935.9728, train_label_loss: 0.0821, 
epoch: 13, [batch: 1225 / 1750], examples_per_second: 1905.6687, train_label_loss: 0.0415, 
epoch: 13, [batch: 1400 / 1750], examples_per_second: 1872.1592, train_label_loss: 0.1598, 
epoch: 13, [batch: 1575 / 1750], examples_per_second: 1840.8565, train_label_loss: 0.0488, 
=============================================================
epoch: 13, source_val_acc_label: 0.8444, source_val_label_loss: 0.4892, target_val_acc_label: 0.0598, target_val_label_loss: 979.6937, 
=============================================================
epoch: 14, [batch: 1 / 1750], examples_per_second: 3.7828, train_label_loss: 0.0251, 
epoch: 14, [batch: 175 / 1750], examples_per_second: 2301.6517, train_label_loss: 0.0191, 
epoch: 14, [batch: 350 / 1750], examples_per_second: 2272.9647, train_label_loss: 0.0156, 
epoch: 14, [batch: 525 / 1750], examples_per_second: 2251.5539, train_label_loss: 0.0465, 
epoch: 14, [batch: 700 / 1750], examples_per_second: 2244.8376, train_label_loss: 0.0138, 
epoch: 14, [batch: 875 / 1750], examples_per_second: 2221.0717, train_label_loss: 0.0283, 
epoch: 14, [batch: 1050 / 1750], examples_per_second: 2204.8651, train_label_loss: 0.0516, 
epoch: 14, [batch: 1225 / 1750], examples_per_second: 2183.6289, train_label_loss: 0.0151, 
epoch: 14, [batch: 1400 / 1750], examples_per_second: 2166.7665, train_label_loss: 0.0169, 
epoch: 14, [batch: 1575 / 1750], examples_per_second: 2143.9360, train_label_loss: 0.0240, 
=============================================================
epoch: 14, source_val_acc_label: 0.8518, source_val_label_loss: 0.4603, target_val_acc_label: 0.0606, target_val_label_loss: 916.0663, 
=============================================================
epoch: 15, [batch: 1 / 1750], examples_per_second: 3.3096, train_label_loss: 0.0126, 
epoch: 15, [batch: 175 / 1750], examples_per_second: 2301.5058, train_label_loss: 0.0296, 
epoch: 15, [batch: 350 / 1750], examples_per_second: 2296.7312, train_label_loss: 0.0085, 
epoch: 15, [batch: 525 / 1750], examples_per_second: 2270.2096, train_label_loss: 0.0240, 
epoch: 15, [batch: 700 / 1750], examples_per_second: 2260.1951, train_label_loss: 0.0132, 
epoch: 15, [batch: 875 / 1750], examples_per_second: 2231.2676, train_label_loss: 0.0045, 
epoch: 15, [batch: 1050 / 1750], examples_per_second: 2222.9436, train_label_loss: 0.0170, 
epoch: 15, [batch: 1225 / 1750], examples_per_second: 2198.1256, train_label_loss: 0.0495, 
epoch: 15, [batch: 1400 / 1750], examples_per_second: 2202.6097, train_label_loss: 0.1643, 
epoch: 15, [batch: 1575 / 1750], examples_per_second: 2166.6846, train_label_loss: 0.0345, 
=============================================================
epoch: 15, source_val_acc_label: 0.8552, source_val_label_loss: 0.4716, target_val_acc_label: 0.0595, target_val_label_loss: 991.5664, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.883 Target Test Label Accuracy: 0.058029166666666666
Source Val Label Accuracy: 0.882 Target Val Label Accuracy: 0.05784583333333333
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
