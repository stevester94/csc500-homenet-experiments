[CONDUCTOR]: Begin experiment at /mnt/wd500GB/CSC500/csc500-super-repo/csc500-homenet-experiments/oracle_cnn_1/results/158
WARNING: CPU random generator seem to be failing, disable hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(oracle_cnn_driver.py:481550): Gdk-CRITICAL **: 04:28:34.659: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1750], examples_per_second: 633.7026, train_label_loss: 2.7577, 
epoch: 1, [batch: 175 / 1750], examples_per_second: 2204.9803, train_label_loss: 1.6149, 
epoch: 1, [batch: 350 / 1750], examples_per_second: 2295.0898, train_label_loss: 1.1273, 
epoch: 1, [batch: 525 / 1750], examples_per_second: 2282.4414, train_label_loss: 0.9468, 
epoch: 1, [batch: 700 / 1750], examples_per_second: 2254.9395, train_label_loss: 0.8375, 
epoch: 1, [batch: 875 / 1750], examples_per_second: 2255.0147, train_label_loss: 0.4706, 
epoch: 1, [batch: 1050 / 1750], examples_per_second: 2234.8761, train_label_loss: 0.4564, 
epoch: 1, [batch: 1225 / 1750], examples_per_second: 2213.0905, train_label_loss: 0.4052, 
epoch: 1, [batch: 1400 / 1750], examples_per_second: 2203.4503, train_label_loss: 0.5513, 
epoch: 1, [batch: 1575 / 1750], examples_per_second: 2171.9012, train_label_loss: 0.4084, 
=============================================================
epoch: 1, source_val_acc_label: 0.8986, source_val_label_loss: 0.3148, target_val_acc_label: 0.0555, target_val_label_loss: 115.0204, 
=============================================================
New best
epoch: 2, [batch: 1 / 1750], examples_per_second: 3.3455, train_label_loss: 0.2767, 
epoch: 2, [batch: 175 / 1750], examples_per_second: 1939.2614, train_label_loss: 0.3140, 
epoch: 2, [batch: 350 / 1750], examples_per_second: 2866.1570, train_label_loss: 0.4237, 
epoch: 2, [batch: 525 / 1750], examples_per_second: 3919.4655, train_label_loss: 0.2582, 
epoch: 2, [batch: 700 / 1750], examples_per_second: 3914.8818, train_label_loss: 0.2774, 
epoch: 2, [batch: 875 / 1750], examples_per_second: 3917.6056, train_label_loss: 0.5684, 
epoch: 2, [batch: 1050 / 1750], examples_per_second: 3913.4513, train_label_loss: 0.2007, 
epoch: 2, [batch: 1225 / 1750], examples_per_second: 3909.6107, train_label_loss: 0.2724, 
epoch: 2, [batch: 1400 / 1750], examples_per_second: 3902.4583, train_label_loss: 0.2474, 
epoch: 2, [batch: 1575 / 1750], examples_per_second: 3905.1360, train_label_loss: 0.3463, 
=============================================================
epoch: 2, source_val_acc_label: 0.9287, source_val_label_loss: 0.2048, target_val_acc_label: 0.0527, target_val_label_loss: 166.2635, 
=============================================================
New best
epoch: 3, [batch: 1 / 1750], examples_per_second: 7.3362, train_label_loss: 0.2089, 
epoch: 3, [batch: 175 / 1750], examples_per_second: 3899.7395, train_label_loss: 0.1857, 
epoch: 3, [batch: 350 / 1750], examples_per_second: 3908.6683, train_label_loss: 0.1505, 
epoch: 3, [batch: 525 / 1750], examples_per_second: 3901.0324, train_label_loss: 0.1683, 
epoch: 3, [batch: 700 / 1750], examples_per_second: 3082.4696, train_label_loss: 0.1569, 
epoch: 3, [batch: 875 / 1750], examples_per_second: 2305.6550, train_label_loss: 0.2113, 
epoch: 3, [batch: 1050 / 1750], examples_per_second: 2355.3356, train_label_loss: 0.2519, 
epoch: 3, [batch: 1225 / 1750], examples_per_second: 2292.6404, train_label_loss: 0.2763, 
epoch: 3, [batch: 1400 / 1750], examples_per_second: 2277.2838, train_label_loss: 0.2158, 
epoch: 3, [batch: 1575 / 1750], examples_per_second: 2277.8611, train_label_loss: 0.3459, 
=============================================================
epoch: 3, source_val_acc_label: 0.9225, source_val_label_loss: 0.2059, target_val_acc_label: 0.0495, target_val_label_loss: 225.7382, 
=============================================================
epoch: 4, [batch: 1 / 1750], examples_per_second: 3.8151, train_label_loss: 0.0782, 
epoch: 4, [batch: 175 / 1750], examples_per_second: 2146.5796, train_label_loss: 0.1417, 
epoch: 4, [batch: 350 / 1750], examples_per_second: 2118.9156, train_label_loss: 0.1056, 
epoch: 4, [batch: 525 / 1750], examples_per_second: 2123.8079, train_label_loss: 0.1824, 
epoch: 4, [batch: 700 / 1750], examples_per_second: 2101.4182, train_label_loss: 0.0815, 
epoch: 4, [batch: 875 / 1750], examples_per_second: 2068.6364, train_label_loss: 0.2181, 
epoch: 4, [batch: 1050 / 1750], examples_per_second: 2060.3283, train_label_loss: 0.0711, 
epoch: 4, [batch: 1225 / 1750], examples_per_second: 2046.5617, train_label_loss: 0.0969, 
epoch: 4, [batch: 1400 / 1750], examples_per_second: 1994.5044, train_label_loss: 0.1069, 
epoch: 4, [batch: 1575 / 1750], examples_per_second: 1986.2861, train_label_loss: 0.2751, 
=============================================================
epoch: 4, source_val_acc_label: 0.9305, source_val_label_loss: 0.1825, target_val_acc_label: 0.0521, target_val_label_loss: 276.5391, 
=============================================================
New best
epoch: 5, [batch: 1 / 1750], examples_per_second: 3.0750, train_label_loss: 0.0905, 
epoch: 5, [batch: 175 / 1750], examples_per_second: 2225.3594, train_label_loss: 0.0888, 
epoch: 5, [batch: 350 / 1750], examples_per_second: 2001.3514, train_label_loss: 0.0802, 
epoch: 5, [batch: 525 / 1750], examples_per_second: 3738.3189, train_label_loss: 0.0771, 
epoch: 5, [batch: 700 / 1750], examples_per_second: 2350.8232, train_label_loss: 0.0246, 
epoch: 5, [batch: 875 / 1750], examples_per_second: 2293.2459, train_label_loss: 0.1082, 
epoch: 5, [batch: 1050 / 1750], examples_per_second: 2256.6251, train_label_loss: 0.3381, 
epoch: 5, [batch: 1225 / 1750], examples_per_second: 2257.6277, train_label_loss: 0.0625, 
epoch: 5, [batch: 1400 / 1750], examples_per_second: 2230.4812, train_label_loss: 0.0484, 
epoch: 5, [batch: 1575 / 1750], examples_per_second: 2209.7678, train_label_loss: 0.1015, 
=============================================================
epoch: 5, source_val_acc_label: 0.9285, source_val_label_loss: 0.1921, target_val_acc_label: 0.0469, target_val_label_loss: 337.7167, 
=============================================================
epoch: 6, [batch: 1 / 1750], examples_per_second: 3.5307, train_label_loss: 0.0804, 
epoch: 6, [batch: 175 / 1750], examples_per_second: 2041.9010, train_label_loss: 0.0414, 
epoch: 6, [batch: 350 / 1750], examples_per_second: 2015.6254, train_label_loss: 0.0364, 
epoch: 6, [batch: 525 / 1750], examples_per_second: 1970.5325, train_label_loss: 0.0562, 
epoch: 6, [batch: 700 / 1750], examples_per_second: 1953.3591, train_label_loss: 0.0407, 
epoch: 6, [batch: 875 / 1750], examples_per_second: 2296.1036, train_label_loss: 0.0554, 
epoch: 6, [batch: 1050 / 1750], examples_per_second: 2295.2330, train_label_loss: 0.0818, 
epoch: 6, [batch: 1225 / 1750], examples_per_second: 2291.0289, train_label_loss: 0.0587, 
epoch: 6, [batch: 1400 / 1750], examples_per_second: 2248.3452, train_label_loss: 0.0503, 
epoch: 6, [batch: 1575 / 1750], examples_per_second: 2270.8306, train_label_loss: 0.1185, 
=============================================================
epoch: 6, source_val_acc_label: 0.9242, source_val_label_loss: 0.2098, target_val_acc_label: 0.0476, target_val_label_loss: 360.6066, 
=============================================================
epoch: 7, [batch: 1 / 1750], examples_per_second: 3.6170, train_label_loss: 0.0700, 
epoch: 7, [batch: 175 / 1750], examples_per_second: 2067.0006, train_label_loss: 0.0207, 
epoch: 7, [batch: 350 / 1750], examples_per_second: 2048.2604, train_label_loss: 0.0950, 
epoch: 7, [batch: 525 / 1750], examples_per_second: 2011.5338, train_label_loss: 0.0402, 
epoch: 7, [batch: 700 / 1750], examples_per_second: 1995.9890, train_label_loss: 0.0262, 
epoch: 7, [batch: 875 / 1750], examples_per_second: 1972.0279, train_label_loss: 0.1134, 
epoch: 7, [batch: 1050 / 1750], examples_per_second: 2115.5836, train_label_loss: 0.0181, 
epoch: 7, [batch: 1225 / 1750], examples_per_second: 3902.5235, train_label_loss: 0.1534, 
epoch: 7, [batch: 1400 / 1750], examples_per_second: 3905.3175, train_label_loss: 0.0570, 
epoch: 7, [batch: 1575 / 1750], examples_per_second: 3902.4868, train_label_loss: 0.1769, 
=============================================================
epoch: 7, source_val_acc_label: 0.9183, source_val_label_loss: 0.2385, target_val_acc_label: 0.0474, target_val_label_loss: 396.0760, 
=============================================================
epoch: 8, [batch: 1 / 1750], examples_per_second: 7.3686, train_label_loss: 0.0666, 
epoch: 8, [batch: 175 / 1750], examples_per_second: 3903.6125, train_label_loss: 0.0423, 
epoch: 8, [batch: 350 / 1750], examples_per_second: 3904.2610, train_label_loss: 0.0357, 
epoch: 8, [batch: 525 / 1750], examples_per_second: 3904.7478, train_label_loss: 0.0664, 
epoch: 8, [batch: 700 / 1750], examples_per_second: 3901.9802, train_label_loss: 0.0103, 
epoch: 8, [batch: 875 / 1750], examples_per_second: 3905.8802, train_label_loss: 0.0851, 
epoch: 8, [batch: 1050 / 1750], examples_per_second: 3907.0373, train_label_loss: 0.0081, 
epoch: 8, [batch: 1225 / 1750], examples_per_second: 3907.2154, train_label_loss: 0.0221, 
epoch: 8, [batch: 1400 / 1750], examples_per_second: 3901.9834, train_label_loss: 0.0364, 
epoch: 8, [batch: 1575 / 1750], examples_per_second: 2461.1422, train_label_loss: 0.0083, 
=============================================================
epoch: 8, source_val_acc_label: 0.9270, source_val_label_loss: 0.2159, target_val_acc_label: 0.0478, target_val_label_loss: 376.6729, 
=============================================================
epoch: 9, [batch: 1 / 1750], examples_per_second: 3.9924, train_label_loss: 0.0222, 
epoch: 9, [batch: 175 / 1750], examples_per_second: 2238.8764, train_label_loss: 0.0476, 
epoch: 9, [batch: 350 / 1750], examples_per_second: 2196.8683, train_label_loss: 0.0157, 
epoch: 9, [batch: 525 / 1750], examples_per_second: 2165.2433, train_label_loss: 0.0839, 
epoch: 9, [batch: 700 / 1750], examples_per_second: 2204.7771, train_label_loss: 0.4383, 
epoch: 9, [batch: 875 / 1750], examples_per_second: 2168.6701, train_label_loss: 0.0703, 
epoch: 9, [batch: 1050 / 1750], examples_per_second: 2151.8997, train_label_loss: 0.0118, 
epoch: 9, [batch: 1225 / 1750], examples_per_second: 2136.0687, train_label_loss: 0.0265, 
epoch: 9, [batch: 1400 / 1750], examples_per_second: 2106.4130, train_label_loss: 0.0096, 
epoch: 9, [batch: 1575 / 1750], examples_per_second: 2107.2208, train_label_loss: 0.0115, 
=============================================================
epoch: 9, source_val_acc_label: 0.9257, source_val_label_loss: 0.2264, target_val_acc_label: 0.0480, target_val_label_loss: 418.2822, 
=============================================================
epoch: 10, [batch: 1 / 1750], examples_per_second: 3.2189, train_label_loss: 0.0164, 
epoch: 10, [batch: 175 / 1750], examples_per_second: 1852.4976, train_label_loss: 0.0867, 
epoch: 10, [batch: 350 / 1750], examples_per_second: 1824.2359, train_label_loss: 0.0146, 
epoch: 10, [batch: 525 / 1750], examples_per_second: 1789.5825, train_label_loss: 0.0108, 
epoch: 10, [batch: 700 / 1750], examples_per_second: 2209.8409, train_label_loss: 0.1163, 
epoch: 10, [batch: 875 / 1750], examples_per_second: 2062.3816, train_label_loss: 0.0110, 
epoch: 10, [batch: 1050 / 1750], examples_per_second: 2214.6989, train_label_loss: 0.0090, 
epoch: 10, [batch: 1225 / 1750], examples_per_second: 2006.1963, train_label_loss: 0.0155, 
epoch: 10, [batch: 1400 / 1750], examples_per_second: 3772.0754, train_label_loss: 0.0237, 
epoch: 10, [batch: 1575 / 1750], examples_per_second: 2347.9752, train_label_loss: 0.0183, 
=============================================================
epoch: 10, source_val_acc_label: 0.9283, source_val_label_loss: 0.2238, target_val_acc_label: 0.0492, target_val_label_loss: 490.6787, 
=============================================================
epoch: 11, [batch: 1 / 1750], examples_per_second: 3.7684, train_label_loss: 0.0165, 
epoch: 11, [batch: 175 / 1750], examples_per_second: 2142.5851, train_label_loss: 0.0059, 
epoch: 11, [batch: 350 / 1750], examples_per_second: 2131.5050, train_label_loss: 0.0040, 
epoch: 11, [batch: 525 / 1750], examples_per_second: 2102.4124, train_label_loss: 0.0561, 
epoch: 11, [batch: 700 / 1750], examples_per_second: 2076.9958, train_label_loss: 0.0736, 
epoch: 11, [batch: 875 / 1750], examples_per_second: 2061.9959, train_label_loss: 0.0091, 
epoch: 11, [batch: 1050 / 1750], examples_per_second: 2047.2096, train_label_loss: 0.0408, 
epoch: 11, [batch: 1225 / 1750], examples_per_second: 2017.0497, train_label_loss: 0.0194, 
epoch: 11, [batch: 1400 / 1750], examples_per_second: 1986.9011, train_label_loss: 0.0310, 
epoch: 11, [batch: 1575 / 1750], examples_per_second: 1959.0653, train_label_loss: 0.0048, 
=============================================================
epoch: 11, source_val_acc_label: 0.9231, source_val_label_loss: 0.2473, target_val_acc_label: 0.0492, target_val_label_loss: 448.3859, 
=============================================================
epoch: 12, [batch: 1 / 1750], examples_per_second: 3.8222, train_label_loss: 0.0418, 
epoch: 12, [batch: 175 / 1750], examples_per_second: 2172.2982, train_label_loss: 0.0113, 
epoch: 12, [batch: 350 / 1750], examples_per_second: 2157.2413, train_label_loss: 0.0088, 
epoch: 12, [batch: 525 / 1750], examples_per_second: 2137.3721, train_label_loss: 0.0310, 
epoch: 12, [batch: 700 / 1750], examples_per_second: 2121.6996, train_label_loss: 0.0097, 
epoch: 12, [batch: 875 / 1750], examples_per_second: 2081.0316, train_label_loss: 0.0271, 
epoch: 12, [batch: 1050 / 1750], examples_per_second: 2078.4923, train_label_loss: 0.0386, 
epoch: 12, [batch: 1225 / 1750], examples_per_second: 2054.4701, train_label_loss: 0.0027, 
epoch: 12, [batch: 1400 / 1750], examples_per_second: 2032.5627, train_label_loss: 0.0315, 
epoch: 12, [batch: 1575 / 1750], examples_per_second: 1997.6159, train_label_loss: 0.0403, 
=============================================================
epoch: 12, source_val_acc_label: 0.9257, source_val_label_loss: 0.2387, target_val_acc_label: 0.0490, target_val_label_loss: 484.8917, 
=============================================================
epoch: 13, [batch: 1 / 1750], examples_per_second: 5.4380, train_label_loss: 0.0312, 
epoch: 13, [batch: 175 / 1750], examples_per_second: 3909.7752, train_label_loss: 0.0163, 
epoch: 13, [batch: 350 / 1750], examples_per_second: 3905.2269, train_label_loss: 0.0111, 
epoch: 13, [batch: 525 / 1750], examples_per_second: 3903.7357, train_label_loss: 0.0125, 
epoch: 13, [batch: 700 / 1750], examples_per_second: 3906.1748, train_label_loss: 0.0023, 
epoch: 13, [batch: 875 / 1750], examples_per_second: 3903.6630, train_label_loss: 0.0466, 
epoch: 13, [batch: 1050 / 1750], examples_per_second: 3905.8633, train_label_loss: 0.0542, 
epoch: 13, [batch: 1225 / 1750], examples_per_second: 3901.4416, train_label_loss: 0.0092, 
epoch: 13, [batch: 1400 / 1750], examples_per_second: 3906.6331, train_label_loss: 0.0233, 
epoch: 13, [batch: 1575 / 1750], examples_per_second: 3902.4732, train_label_loss: 0.0165, 
=============================================================
epoch: 13, source_val_acc_label: 0.9202, source_val_label_loss: 0.2613, target_val_acc_label: 0.0516, target_val_label_loss: 593.6252, 
=============================================================
epoch: 14, [batch: 1 / 1750], examples_per_second: 5.8712, train_label_loss: 0.0131, 
epoch: 14, [batch: 175 / 1750], examples_per_second: 2331.0526, train_label_loss: 0.0025, 
epoch: 14, [batch: 350 / 1750], examples_per_second: 2296.5169, train_label_loss: 0.0064, 
epoch: 14, [batch: 525 / 1750], examples_per_second: 2273.8564, train_label_loss: 0.0426, 
epoch: 14, [batch: 700 / 1750], examples_per_second: 2249.0647, train_label_loss: 0.0302, 
epoch: 14, [batch: 875 / 1750], examples_per_second: 2228.1917, train_label_loss: 0.0065, 
epoch: 14, [batch: 1050 / 1750], examples_per_second: 2258.2672, train_label_loss: 0.0072, 
epoch: 14, [batch: 1225 / 1750], examples_per_second: 2204.3705, train_label_loss: 0.0168, 
epoch: 14, [batch: 1400 / 1750], examples_per_second: 2255.9416, train_label_loss: 0.0231, 
epoch: 14, [batch: 1575 / 1750], examples_per_second: 2166.0910, train_label_loss: 0.0075, 
=============================================================
epoch: 14, source_val_acc_label: 0.9205, source_val_label_loss: 0.2707, target_val_acc_label: 0.0517, target_val_label_loss: 593.4669, 
=============================================================
epoch: 15, [batch: 1 / 1750], examples_per_second: 3.5831, train_label_loss: 0.0671, 
epoch: 15, [batch: 175 / 1750], examples_per_second: 2014.6407, train_label_loss: 0.0079, 
epoch: 15, [batch: 350 / 1750], examples_per_second: 2013.9830, train_label_loss: 0.0113, 
epoch: 15, [batch: 525 / 1750], examples_per_second: 1975.3742, train_label_loss: 0.0172, 
epoch: 15, [batch: 700 / 1750], examples_per_second: 1954.5480, train_label_loss: 0.0044, 
epoch: 15, [batch: 875 / 1750], examples_per_second: 1932.0469, train_label_loss: 0.0227, 
epoch: 15, [batch: 1050 / 1750], examples_per_second: 1903.7551, train_label_loss: 0.0140, 
epoch: 15, [batch: 1225 / 1750], examples_per_second: 1883.6492, train_label_loss: 0.0095, 
epoch: 15, [batch: 1400 / 1750], examples_per_second: 1833.8666, train_label_loss: 0.0172, 
epoch: 15, [batch: 1575 / 1750], examples_per_second: 1807.1446, train_label_loss: 0.0035, 
=============================================================
epoch: 15, source_val_acc_label: 0.9180, source_val_label_loss: 0.2786, target_val_acc_label: 0.0518, target_val_label_loss: 655.9231, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.9307083333333334 Target Test Label Accuracy: 0.05169583333333334
Source Val Label Accuracy: 0.9305 Target Val Label Accuracy: 0.052125
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
