[CONDUCTOR]: Begin experiment at /mnt/wd500GB/CSC500/csc500-super-repo/csc500-homenet-experiments/oracle_cnn_1/results/52
WARNING: CPU random generator seem to be failing, disable hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff
Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(oracle_cnn_driver.py:451142): Gdk-CRITICAL **: 15:37:14.950: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 1750], examples_per_second: 759.4121, train_label_loss: 2.7722, 
epoch: 1, [batch: 175 / 1750], examples_per_second: 3939.8989, train_label_loss: 1.7554, 
epoch: 1, [batch: 350 / 1750], examples_per_second: 3966.0530, train_label_loss: 1.2694, 
epoch: 1, [batch: 525 / 1750], examples_per_second: 3952.2303, train_label_loss: 1.0752, 
epoch: 1, [batch: 700 / 1750], examples_per_second: 3967.8332, train_label_loss: 1.0161, 
epoch: 1, [batch: 875 / 1750], examples_per_second: 3945.2277, train_label_loss: 0.9061, 
epoch: 1, [batch: 1050 / 1750], examples_per_second: 3947.5537, train_label_loss: 0.7984, 
epoch: 1, [batch: 1225 / 1750], examples_per_second: 3924.0593, train_label_loss: 0.6406, 
epoch: 1, [batch: 1400 / 1750], examples_per_second: 3937.8092, train_label_loss: 0.6334, 
epoch: 1, [batch: 1575 / 1750], examples_per_second: 3924.9760, train_label_loss: 0.5927, 
=============================================================
epoch: 1, source_val_acc_label: 0.8314, source_val_label_loss: 0.5277, target_val_acc_label: 0.0658, target_val_label_loss: 158.5320, 
=============================================================
New best
epoch: 2, [batch: 1 / 1750], examples_per_second: 7.2943, train_label_loss: 0.4472, 
epoch: 2, [batch: 175 / 1750], examples_per_second: 3933.8546, train_label_loss: 0.5522, 
epoch: 2, [batch: 350 / 1750], examples_per_second: 3919.0227, train_label_loss: 0.4260, 
epoch: 2, [batch: 525 / 1750], examples_per_second: 3934.0109, train_label_loss: 0.4790, 
epoch: 2, [batch: 700 / 1750], examples_per_second: 3919.4220, train_label_loss: 0.4411, 
epoch: 2, [batch: 875 / 1750], examples_per_second: 3937.2940, train_label_loss: 0.5294, 
epoch: 2, [batch: 1050 / 1750], examples_per_second: 3926.6072, train_label_loss: 0.4433, 
epoch: 2, [batch: 1225 / 1750], examples_per_second: 3934.0221, train_label_loss: 0.4697, 
epoch: 2, [batch: 1400 / 1750], examples_per_second: 3933.5899, train_label_loss: 0.2826, 
epoch: 2, [batch: 1575 / 1750], examples_per_second: 3932.1503, train_label_loss: 0.4016, 
=============================================================
epoch: 2, source_val_acc_label: 0.8663, source_val_label_loss: 0.3840, target_val_acc_label: 0.0642, target_val_label_loss: 226.0997, 
=============================================================
New best
epoch: 3, [batch: 1 / 1750], examples_per_second: 7.3277, train_label_loss: 0.3768, 
epoch: 3, [batch: 175 / 1750], examples_per_second: 3941.8667, train_label_loss: 0.2977, 
epoch: 3, [batch: 350 / 1750], examples_per_second: 3930.7000, train_label_loss: 0.3334, 
epoch: 3, [batch: 525 / 1750], examples_per_second: 3925.7501, train_label_loss: 0.2268, 
epoch: 3, [batch: 700 / 1750], examples_per_second: 3931.7715, train_label_loss: 0.3562, 
epoch: 3, [batch: 875 / 1750], examples_per_second: 3938.7941, train_label_loss: 0.2888, 
epoch: 3, [batch: 1050 / 1750], examples_per_second: 3930.5754, train_label_loss: 0.1942, 
epoch: 3, [batch: 1225 / 1750], examples_per_second: 3935.5032, train_label_loss: 0.3221, 
epoch: 3, [batch: 1400 / 1750], examples_per_second: 3915.2087, train_label_loss: 0.2045, 
epoch: 3, [batch: 1575 / 1750], examples_per_second: 3926.8869, train_label_loss: 0.4614, 
=============================================================
epoch: 3, source_val_acc_label: 0.8632, source_val_label_loss: 0.3600, target_val_acc_label: 0.0583, target_val_label_loss: 311.1228, 
=============================================================
New best
epoch: 4, [batch: 1 / 1750], examples_per_second: 7.3130, train_label_loss: 0.2418, 
epoch: 4, [batch: 175 / 1750], examples_per_second: 3919.3324, train_label_loss: 0.1369, 
epoch: 4, [batch: 350 / 1750], examples_per_second: 3940.3852, train_label_loss: 0.3498, 
epoch: 4, [batch: 525 / 1750], examples_per_second: 3937.1989, train_label_loss: 0.3558, 
epoch: 4, [batch: 700 / 1750], examples_per_second: 3918.0542, train_label_loss: 0.1422, 
epoch: 4, [batch: 875 / 1750], examples_per_second: 3928.5798, train_label_loss: 0.3377, 
epoch: 4, [batch: 1050 / 1750], examples_per_second: 3911.4040, train_label_loss: 0.1793, 
epoch: 4, [batch: 1225 / 1750], examples_per_second: 3933.3303, train_label_loss: 0.2445, 
epoch: 4, [batch: 1400 / 1750], examples_per_second: 3919.4213, train_label_loss: 0.1987, 
epoch: 4, [batch: 1575 / 1750], examples_per_second: 3944.1210, train_label_loss: 0.4213, 
=============================================================
epoch: 4, source_val_acc_label: 0.8762, source_val_label_loss: 0.3247, target_val_acc_label: 0.0611, target_val_label_loss: 370.2166, 
=============================================================
New best
epoch: 5, [batch: 1 / 1750], examples_per_second: 7.3121, train_label_loss: 0.1605, 
epoch: 5, [batch: 175 / 1750], examples_per_second: 3921.3257, train_label_loss: 0.1225, 
epoch: 5, [batch: 350 / 1750], examples_per_second: 3933.3774, train_label_loss: 0.1396, 
epoch: 5, [batch: 525 / 1750], examples_per_second: 3922.1492, train_label_loss: 0.1390, 
epoch: 5, [batch: 700 / 1750], examples_per_second: 3932.9984, train_label_loss: 0.2214, 
epoch: 5, [batch: 875 / 1750], examples_per_second: 3912.3109, train_label_loss: 0.2360, 
epoch: 5, [batch: 1050 / 1750], examples_per_second: 3930.7444, train_label_loss: 0.1965, 
epoch: 5, [batch: 1225 / 1750], examples_per_second: 3850.8293, train_label_loss: 0.1710, 
epoch: 5, [batch: 1400 / 1750], examples_per_second: 3813.4441, train_label_loss: 0.2725, 
epoch: 5, [batch: 1575 / 1750], examples_per_second: 3930.3366, train_label_loss: 0.2153, 
=============================================================
epoch: 5, source_val_acc_label: 0.8679, source_val_label_loss: 0.3351, target_val_acc_label: 0.0590, target_val_label_loss: 426.1908, 
=============================================================
epoch: 6, [batch: 1 / 1750], examples_per_second: 7.3488, train_label_loss: 0.0876, 
epoch: 6, [batch: 175 / 1750], examples_per_second: 3909.8125, train_label_loss: 0.0687, 
epoch: 6, [batch: 350 / 1750], examples_per_second: 3020.7853, train_label_loss: 0.1085, 
epoch: 6, [batch: 525 / 1750], examples_per_second: 2324.2569, train_label_loss: 0.1187, 
epoch: 6, [batch: 700 / 1750], examples_per_second: 2278.8634, train_label_loss: 0.1525, 
epoch: 6, [batch: 875 / 1750], examples_per_second: 2284.1827, train_label_loss: 0.1925, 
epoch: 6, [batch: 1050 / 1750], examples_per_second: 2301.0968, train_label_loss: 0.1588, 
epoch: 6, [batch: 1225 / 1750], examples_per_second: 2261.3101, train_label_loss: 0.1749, 
epoch: 6, [batch: 1400 / 1750], examples_per_second: 2274.7764, train_label_loss: 0.1828, 
epoch: 6, [batch: 1575 / 1750], examples_per_second: 2236.3961, train_label_loss: 0.0761, 
=============================================================
epoch: 6, source_val_acc_label: 0.8652, source_val_label_loss: 0.3561, target_val_acc_label: 0.0579, target_val_label_loss: 496.6028, 
=============================================================
epoch: 7, [batch: 1 / 1750], examples_per_second: 3.7101, train_label_loss: 0.0957, 
epoch: 7, [batch: 175 / 1750], examples_per_second: 2087.7130, train_label_loss: 0.1356, 
epoch: 7, [batch: 350 / 1750], examples_per_second: 2085.9677, train_label_loss: 0.0735, 
epoch: 7, [batch: 525 / 1750], examples_per_second: 2084.2903, train_label_loss: 0.1080, 
epoch: 7, [batch: 700 / 1750], examples_per_second: 2039.9377, train_label_loss: 0.0390, 
epoch: 7, [batch: 875 / 1750], examples_per_second: 2026.3994, train_label_loss: 0.0543, 
epoch: 7, [batch: 1050 / 1750], examples_per_second: 1992.7660, train_label_loss: 0.0711, 
epoch: 7, [batch: 1225 / 1750], examples_per_second: 1979.3514, train_label_loss: 0.0839, 
epoch: 7, [batch: 1400 / 1750], examples_per_second: 1948.4998, train_label_loss: 0.0632, 
epoch: 7, [batch: 1575 / 1750], examples_per_second: 1937.1298, train_label_loss: 0.1387, 
=============================================================
epoch: 7, source_val_acc_label: 0.8658, source_val_label_loss: 0.3649, target_val_acc_label: 0.0579, target_val_label_loss: 536.1370, 
=============================================================
epoch: 8, [batch: 1 / 1750], examples_per_second: 3.1896, train_label_loss: 0.0451, 
epoch: 8, [batch: 175 / 1750], examples_per_second: 3656.0847, train_label_loss: 0.0516, 
epoch: 8, [batch: 350 / 1750], examples_per_second: 2321.5466, train_label_loss: 0.1425, 
epoch: 8, [batch: 525 / 1750], examples_per_second: 2300.5350, train_label_loss: 0.0402, 
epoch: 8, [batch: 700 / 1750], examples_per_second: 2274.5689, train_label_loss: 0.0375, 
epoch: 8, [batch: 875 / 1750], examples_per_second: 2264.9840, train_label_loss: 0.1688, 
epoch: 8, [batch: 1050 / 1750], examples_per_second: 2242.9324, train_label_loss: 0.0757, 
epoch: 8, [batch: 1225 / 1750], examples_per_second: 2232.9192, train_label_loss: 0.0494, 
epoch: 8, [batch: 1400 / 1750], examples_per_second: 2216.1458, train_label_loss: 0.0644, 
epoch: 8, [batch: 1575 / 1750], examples_per_second: 2171.4754, train_label_loss: 0.1228, 
=============================================================
epoch: 8, source_val_acc_label: 0.8648, source_val_label_loss: 0.3793, target_val_acc_label: 0.0580, target_val_label_loss: 624.8489, 
=============================================================
epoch: 9, [batch: 1 / 1750], examples_per_second: 3.3814, train_label_loss: 0.0433, 
epoch: 9, [batch: 175 / 1750], examples_per_second: 1977.1441, train_label_loss: 0.0930, 
epoch: 9, [batch: 350 / 1750], examples_per_second: 2088.0573, train_label_loss: 0.0666, 
epoch: 9, [batch: 525 / 1750], examples_per_second: 2308.8066, train_label_loss: 0.2717, 
epoch: 9, [batch: 700 / 1750], examples_per_second: 2292.4518, train_label_loss: 0.0920, 
epoch: 9, [batch: 875 / 1750], examples_per_second: 2276.4541, train_label_loss: 0.0540, 
epoch: 9, [batch: 1050 / 1750], examples_per_second: 2261.2656, train_label_loss: 0.1546, 
epoch: 9, [batch: 1225 / 1750], examples_per_second: 2248.6338, train_label_loss: 0.0953, 
epoch: 9, [batch: 1400 / 1750], examples_per_second: 2226.0965, train_label_loss: 0.0547, 
epoch: 9, [batch: 1575 / 1750], examples_per_second: 2215.2091, train_label_loss: 0.0513, 
=============================================================
epoch: 9, source_val_acc_label: 0.8553, source_val_label_loss: 0.4334, target_val_acc_label: 0.0583, target_val_label_loss: 632.3023, 
=============================================================
epoch: 10, [batch: 1 / 1750], examples_per_second: 3.4237, train_label_loss: 0.0232, 
epoch: 10, [batch: 175 / 1750], examples_per_second: 1999.3235, train_label_loss: 0.0162, 
epoch: 10, [batch: 350 / 1750], examples_per_second: 1994.3598, train_label_loss: 0.0111, 
epoch: 10, [batch: 525 / 1750], examples_per_second: 1987.0972, train_label_loss: 0.0379, 
epoch: 10, [batch: 700 / 1750], examples_per_second: 3929.6830, train_label_loss: 0.0739, 
epoch: 10, [batch: 875 / 1750], examples_per_second: 3934.4876, train_label_loss: 0.0367, 
epoch: 10, [batch: 1050 / 1750], examples_per_second: 3929.2376, train_label_loss: 0.0303, 
epoch: 10, [batch: 1225 / 1750], examples_per_second: 3935.7363, train_label_loss: 0.0852, 
epoch: 10, [batch: 1400 / 1750], examples_per_second: 3938.2357, train_label_loss: 0.1472, 
epoch: 10, [batch: 1575 / 1750], examples_per_second: 3928.3413, train_label_loss: 0.0201, 
=============================================================
epoch: 10, source_val_acc_label: 0.8574, source_val_label_loss: 0.4266, target_val_acc_label: 0.0575, target_val_label_loss: 645.5998, 
=============================================================
epoch: 11, [batch: 1 / 1750], examples_per_second: 7.3651, train_label_loss: 0.0289, 
epoch: 11, [batch: 175 / 1750], examples_per_second: 3941.7289, train_label_loss: 0.0150, 
epoch: 11, [batch: 350 / 1750], examples_per_second: 3932.0885, train_label_loss: 0.0739, 
epoch: 11, [batch: 525 / 1750], examples_per_second: 3936.3464, train_label_loss: 0.0461, 
epoch: 11, [batch: 700 / 1750], examples_per_second: 3934.7721, train_label_loss: 0.0664, 
epoch: 11, [batch: 875 / 1750], examples_per_second: 3769.5882, train_label_loss: 0.0360, 
epoch: 11, [batch: 1050 / 1750], examples_per_second: 2346.7742, train_label_loss: 0.0308, 
epoch: 11, [batch: 1225 / 1750], examples_per_second: 2288.5903, train_label_loss: 0.0239, 
epoch: 11, [batch: 1400 / 1750], examples_per_second: 2300.3231, train_label_loss: 0.1898, 
epoch: 11, [batch: 1575 / 1750], examples_per_second: 2313.5551, train_label_loss: 0.0604, 
=============================================================
epoch: 11, source_val_acc_label: 0.8490, source_val_label_loss: 0.4703, target_val_acc_label: 0.0589, target_val_label_loss: 729.2002, 
=============================================================
epoch: 12, [batch: 1 / 1750], examples_per_second: 3.8383, train_label_loss: 0.0134, 
epoch: 12, [batch: 175 / 1750], examples_per_second: 2193.8916, train_label_loss: 0.0202, 
epoch: 12, [batch: 350 / 1750], examples_per_second: 2138.8114, train_label_loss: 0.0739, 
epoch: 12, [batch: 525 / 1750], examples_per_second: 2132.0791, train_label_loss: 0.0281, 
epoch: 12, [batch: 700 / 1750], examples_per_second: 2150.7155, train_label_loss: 0.0500, 
epoch: 12, [batch: 875 / 1750], examples_per_second: 2089.2910, train_label_loss: 0.0219, 
epoch: 12, [batch: 1050 / 1750], examples_per_second: 2072.2145, train_label_loss: 0.0608, 
epoch: 12, [batch: 1225 / 1750], examples_per_second: 2054.3017, train_label_loss: 0.0155, 
epoch: 12, [batch: 1400 / 1750], examples_per_second: 2034.4050, train_label_loss: 0.0619, 
epoch: 12, [batch: 1575 / 1750], examples_per_second: 2012.9057, train_label_loss: 0.0202, 
=============================================================
epoch: 12, source_val_acc_label: 0.8562, source_val_label_loss: 0.4504, target_val_acc_label: 0.0587, target_val_label_loss: 758.1055, 
=============================================================
epoch: 13, [batch: 1 / 1750], examples_per_second: 3.0602, train_label_loss: 0.0147, 
epoch: 13, [batch: 175 / 1750], examples_per_second: 2095.5943, train_label_loss: 0.0462, 
epoch: 13, [batch: 350 / 1750], examples_per_second: 2208.8000, train_label_loss: 0.0720, 
epoch: 13, [batch: 525 / 1750], examples_per_second: 2044.6033, train_label_loss: 0.0426, 
epoch: 13, [batch: 700 / 1750], examples_per_second: 3239.6114, train_label_loss: 0.0161, 
epoch: 13, [batch: 875 / 1750], examples_per_second: 2539.6226, train_label_loss: 0.0457, 
epoch: 13, [batch: 1050 / 1750], examples_per_second: 2294.9058, train_label_loss: 0.0349, 
epoch: 13, [batch: 1225 / 1750], examples_per_second: 2269.2155, train_label_loss: 0.0273, 
epoch: 13, [batch: 1400 / 1750], examples_per_second: 2275.0814, train_label_loss: 0.0149, 
epoch: 13, [batch: 1575 / 1750], examples_per_second: 2255.5372, train_label_loss: 0.0401, 
=============================================================
epoch: 13, source_val_acc_label: 0.8597, source_val_label_loss: 0.4439, target_val_acc_label: 0.0585, target_val_label_loss: 860.2520, 
=============================================================
epoch: 14, [batch: 1 / 1750], examples_per_second: 3.5698, train_label_loss: 0.0050, 
epoch: 14, [batch: 175 / 1750], examples_per_second: 2069.3622, train_label_loss: 0.0233, 
epoch: 14, [batch: 350 / 1750], examples_per_second: 2042.4678, train_label_loss: 0.0135, 
epoch: 14, [batch: 525 / 1750], examples_per_second: 2018.8847, train_label_loss: 0.0252, 
epoch: 14, [batch: 700 / 1750], examples_per_second: 1992.0521, train_label_loss: 0.0709, 
epoch: 14, [batch: 875 / 1750], examples_per_second: 1961.2733, train_label_loss: 0.0338, 
epoch: 14, [batch: 1050 / 1750], examples_per_second: 2244.2479, train_label_loss: 0.0574, 
epoch: 14, [batch: 1225 / 1750], examples_per_second: 2300.5749, train_label_loss: 0.0194, 
epoch: 14, [batch: 1400 / 1750], examples_per_second: 2284.5724, train_label_loss: 0.0254, 
epoch: 14, [batch: 1575 / 1750], examples_per_second: 2256.7918, train_label_loss: 0.0846, 
=============================================================
epoch: 14, source_val_acc_label: 0.8465, source_val_label_loss: 0.4962, target_val_acc_label: 0.0590, target_val_label_loss: 751.3855, 
=============================================================
epoch: 15, [batch: 1 / 1750], examples_per_second: 3.6443, train_label_loss: 0.0203, 
epoch: 15, [batch: 175 / 1750], examples_per_second: 2094.6666, train_label_loss: 0.0109, 
epoch: 15, [batch: 350 / 1750], examples_per_second: 2068.8585, train_label_loss: 0.0395, 
epoch: 15, [batch: 525 / 1750], examples_per_second: 2042.4098, train_label_loss: 0.0572, 
epoch: 15, [batch: 700 / 1750], examples_per_second: 2021.6054, train_label_loss: 0.0126, 
epoch: 15, [batch: 875 / 1750], examples_per_second: 1991.6373, train_label_loss: 0.0407, 
epoch: 15, [batch: 1050 / 1750], examples_per_second: 1990.1346, train_label_loss: 0.0465, 
epoch: 15, [batch: 1225 / 1750], examples_per_second: 2112.6709, train_label_loss: 0.0497, 
epoch: 15, [batch: 1400 / 1750], examples_per_second: 3917.4789, train_label_loss: 0.0323, 
epoch: 15, [batch: 1575 / 1750], examples_per_second: 3945.5431, train_label_loss: 0.0578, 
=============================================================
epoch: 15, source_val_acc_label: 0.8543, source_val_label_loss: 0.4749, target_val_acc_label: 0.0578, target_val_label_loss: 792.3492, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.8792083333333334 Target Test Label Accuracy: 0.061516666666666664
Source Val Label Accuracy: 0.87625 Target Val Label Accuracy: 0.0610625
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
